{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from numpy import cos, sin, deg2rad, roll, logical_and, where, inner, exp, rad2deg, arctan2, trace, dot, convolve, sqrt, subtract, log, floor, stack, delete, concatenate, max\n",
    "from numpy.linalg import det, lstsq, norm\n",
    "from einops import rearrange\n",
    "from sift import sift\n",
    "from stero import matchKeyPoints\n",
    "from random import shuffle\n",
    "from svd import svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images\n",
    "image1 = cv2.imread('images/test1.jpeg', cv2.IMREAD_GRAYSCALE)\n",
    "image2 = cv2.imread('images/test2.jpeg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# reduce image size\n",
    "xscale = 0.25\n",
    "yscale = 0.25\n",
    "image1_small = cv2.resize(image1, (0,0), fx = xscale, fy = yscale)\n",
    "image2_small = cv2.resize(image2, (0,0), fx = xscale, fy = yscale)\n",
    "\n",
    "# Initialize SIFT detector\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# Detect keypoints and compute descriptors\n",
    "keypoints1, descriptors1 = sift.detectAndCompute(image1, None)\n",
    "keypoints2, descriptors2 = sift.detectAndCompute(image2, None)\n",
    "\n",
    "# keypoints1, descriptors1 = sift(image1_small)\n",
    "# keypoints2, descriptors2 = sift(image2_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_matches = matchKeyPoints(descriptors1, descriptors2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw matches\n",
    "matched_image = cv2.drawMatches(image1, keypoints1, image2, keypoints2, good_matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "matched_image_small = cv2.resize(matched_image, (0,0), fx = 0.5, fy = 0.5)\n",
    "\n",
    "# Display the matched image\n",
    "cv2.imshow('Matches', matched_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 7)\n"
     ]
    }
   ],
   "source": [
    "# rewriting constrian equation from v'*f_m*v = 0 to A*f_v = 0, where f_m is fundamental matrix\n",
    "# and f_v is the unrolled fundamental matrix\n",
    "A = np.zeros((8,9))\n",
    "for i in range(8):\n",
    "    image1_idx = good_matches[i].queryIdx\n",
    "    image2_idx = good_matches[i].trainIdx\n",
    "    u1, v1 = keypoints1[image1_idx].pt\n",
    "    u2, v2 = keypoints2[image1_idx].pt\n",
    "    A[i,:] = np.array([u2*u1, u2*v1, u2, v2*u1, v2*v1, v2, u1, v1, 1])\n",
    "\n",
    "# Solve for non-trival nullspace of matrix A\n",
    "U, S, V = svd(A)\n",
    "f_v = V[:,-1]\n",
    "f_m = f_v.reshape((3,3)) # note: rank of f_m is already 2\n",
    "\n",
    "# decompose fundamental matrix to get essential matrix\n",
    "# need camer intrinsic here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(5)\n",
    "b = (a**2 + a**2)\n",
    "count = (b < 9).sum()\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def load_images(image_paths):\n",
    "    \"\"\"Load a sequence of images.\"\"\"\n",
    "    images = [cv2.imread(path, cv2.IMREAD_GRAYSCALE) for path in image_paths]\n",
    "    return images\n",
    "\n",
    "def detect_and_match_features(img1, img2):\n",
    "    \"\"\"Detect and match features between two images.\"\"\"\n",
    "    orb = cv2.ORB_create()\n",
    "    kp1, des1 = orb.detectAndCompute(img1, None)\n",
    "    kp2, des2 = orb.detectAndCompute(img2, None)\n",
    "    \n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(des1, des2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    \n",
    "    pts1 = np.float32([kp1[m.queryIdx].pt for m in matches])\n",
    "    pts2 = np.float32([kp2[m.trainIdx].pt for m in matches])\n",
    "    return pts1, pts2\n",
    "\n",
    "def compute_rectification_homographies(F, img1, img2, pts1, pts2):\n",
    "    \"\"\"Compute the rectification homographies.\"\"\"\n",
    "    h, w = img1.shape\n",
    "    _, H1, H2 = cv2.stereoRectifyUncalibrated(pts1, pts2, F, (w, h))\n",
    "    return H1, H2\n",
    "\n",
    "def apply_homographies(img1, img2, H1, H2):\n",
    "    \"\"\"Apply the rectifying homographies to the images.\"\"\"\n",
    "    h, w = img1.shape\n",
    "    rectified_img1 = cv2.warpPerspective(img1, H1, (w, h))\n",
    "    rectified_img2 = cv2.warpPerspective(img2, H2, (w, h))\n",
    "    return rectified_img1, rectified_img2\n",
    "\n",
    "def main():\n",
    "    image_paths = ['images/card1.jpeg', 'images/card2.jpeg']\n",
    "    img1, img2 = load_images(image_paths)\n",
    "\n",
    "    pts1, pts2 = detect_and_match_features(img1, img2)\n",
    "    \n",
    "    # Estimate fundamental matrix\n",
    "    F, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_RANSAC)\n",
    "    pts1 = pts1[mask.ravel() == 1]\n",
    "    pts2 = pts2[mask.ravel() == 1]\n",
    "    \n",
    "    # Compute rectification homographies\n",
    "    H1, H2 = compute_rectification_homographies(F, img1, img2, pts1, pts2)\n",
    "    \n",
    "    # Apply homographies to rectify the images\n",
    "    rectified_img1, rectified_img2 = apply_homographies(img1, img2, H1, H2)\n",
    "\n",
    "    xscale = 0.5\n",
    "    yscale = 0.5\n",
    "    \n",
    "    rectified_img1_small = cv2.resize(rectified_img1, (0,0), fx = xscale, fy = yscale)\n",
    "    rectified_img2_small = cv2.resize(rectified_img2, (0,0), fx = xscale, fy = yscale)\n",
    "    \n",
    "    # Display the rectified images\n",
    "    cv2.imshow('Rectified Image 1', rectified_img1_small)\n",
    "    cv2.imshow('Rectified Image 2', rectified_img2_small)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from einops import rearrange\n",
    "a, b = np.ones((30,3)), np.zeros((30,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 27588, 150645])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "b = np.array([[11,22,33],[44,55,66]])\n",
    "c = b\n",
    "np.sum(((b@a)*c), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27588]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = rearrange(b[0,:], 'a -> a 1')\n",
    "y = rearrange(x, 'a b -> b a')\n",
    "y@a@x\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mycv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
